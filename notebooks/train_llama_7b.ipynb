{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CoAL on T5-Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install the main dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers peft tqdm matplotlib sentencepiece bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for training\n",
    "\n",
    "Import **CoALT5Translator** neural network architecture, load the dataset & check it out and start the DNN instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coal_llama import LlamaCoALTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"data.txt\", \"r\").read()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = LlamaCoALTranslator(\n",
    "    model_name=\"t5-base\", # T5-Base can do the job, but if you have the resources, go for bigger versions (large, 3b).\n",
    "    use_4bit=True,\n",
    "    use_peft=True,\n",
    "    batch_size=1, # Due to the fact that Llama is a large model, this has to be set to 1.\n",
    "    lr=2e-4,\n",
    "    num_epochs=3, # It's recommended to set the number of epochs to this number, but you can change if you want.\n",
    "    max_length=512,\n",
    "    output_dir=\"coal_llama_translator\" # You can change the output folder if you want.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CoAL-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.train(\n",
    "    data_string=data,\n",
    "    test_size=0.2,\n",
    "    augment=True,\n",
    "    early_stopping_patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlang to English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important!\n",
    "\n",
    "When **CoAL** is built upon **Llama's** architecture, it seems that the direction \"**c2e**\" fails to generate a correct translation, it may be caused by the LLM itself and it's probably not a problem with **CoAL**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translator.translate(\"...\", direction=\"c2e\")\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English to Conlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translator.translate(\"...\", direction=\"e2c\")\n",
    "translation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
